{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Matthew-Z-Purvis/Satellites/blob/main/Sat.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Aow-KvJLa_Wj"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import random\n",
        "import shutil\n",
        "from collections import defaultdict\n",
        "import numpy as np\n",
        "\n",
        "def clear_directory(directory):\n",
        "    \"\"\"\n",
        "    Delete all files and directories inside the given directory.\n",
        "\n",
        "    :param directory: The directory to clear.\n",
        "    \"\"\"\n",
        "    if os.path.exists(directory):\n",
        "        shutil.rmtree(directory)\n",
        "    os.makedirs(directory)\n",
        "\n",
        "def random_transform(image, original_size):\n",
        "    \"\"\"\n",
        "    Apply random transformations to the image such as stretching, shrinking, and cropping.\n",
        "\n",
        "    :param image: The image to transform.\n",
        "    :param original_size: A tuple (width, height) of the original size.\n",
        "    :return: The transformed image.\n",
        "    \"\"\"\n",
        "    original_width, original_height = original_size\n",
        "\n",
        "    # Ensure the new dimensions are at least the size of the original dimensions\n",
        "    new_width = random.randint(original_width, int(original_width * 1.6))\n",
        "    new_height = random.randint(original_height, int(original_height * 1.6))\n",
        "    image = image.resize((new_width, new_height), Image.LANCZOS)\n",
        "\n",
        "    # Random cropping to original size\n",
        "    left = random.randint(0, max(0, new_width - original_width))\n",
        "    top = random.randint(0, max(0, new_height - original_height))\n",
        "    right = left + original_width\n",
        "    bottom = top + original_height\n",
        "    image = image.crop((left, top, right, bottom))\n",
        "\n",
        "    return image\n",
        "\n",
        "def is_yellow(pixel, threshold=200):\n",
        "    \"\"\"\n",
        "    Check if a pixel is yellow based on a threshold.\n",
        "\n",
        "    :param pixel: The pixel to check (R, G, B).\n",
        "    :param threshold: The threshold for determining yellow.\n",
        "    :return: True if the pixel is yellow, otherwise False.\n",
        "    \"\"\"\n",
        "    r, g, b = pixel\n",
        "    return r > 200 and g > 200 and b < threshold\n",
        "\n",
        "def make_non_yellow_and_adjacent_black(image):\n",
        "    \"\"\"\n",
        "    Make all non-yellow and non-adjacent-to-yellow pixels black in the image.\n",
        "\n",
        "    :param image: The image to process.\n",
        "    :return: The processed image.\n",
        "    \"\"\"\n",
        "    np_image = np.array(image)\n",
        "    yellow_mask = np.apply_along_axis(lambda pixel: is_yellow(pixel), 2, np_image)\n",
        "\n",
        "    # Create a mask for pixels adjacent to yellow pixels\n",
        "    adjacent_mask = np.zeros_like(yellow_mask)\n",
        "\n",
        "    # Dilate the yellow mask to include adjacent pixels\n",
        "    for y in range(1, yellow_mask.shape[0] - 1):\n",
        "        for x in range(1, yellow_mask.shape[1] - 1):\n",
        "            if yellow_mask[y, x]:\n",
        "                adjacent_mask[y-1:y+2, x-1:x+2] = True\n",
        "\n",
        "\n",
        "    combined_mask = yellow_mask | adjacent_mask\n",
        "\n",
        "\n",
        "    np_image[~combined_mask] = [0, 0, 0]\n",
        "\n",
        "    return Image.fromarray(np_image)\n",
        "\n",
        "def crop_top_down_until_yellow(image, crop_box):\n",
        "    \"\"\"\n",
        "    Crop the image from the top down until a yellow pixel is encountered.\n",
        "\n",
        "    :param image: The image to crop.\n",
        "    :param crop_box: The initial crop box.\n",
        "    :return: The cropped image.\n",
        "    \"\"\"\n",
        "    left, upper, right, lower = crop_box\n",
        "    cropped_img = image.crop(crop_box)\n",
        "\n",
        "    for y in range(upper, lower):\n",
        "        row = cropped_img.crop((0, y - upper, right - left, y - upper + 1))\n",
        "        for x in range(row.width):\n",
        "            if is_yellow(row.getpixel((x, 0))):\n",
        "                return image.crop((left, y, right, lower))\n",
        "    return cropped_img\n",
        "\n",
        "def process_and_resize_images(input_directory, output_directory, crop_box, resize_to, train_ratio=0.8):\n",
        "    \"\"\"\n",
        "    Process and resize all images in the input directory and save them to the train and test directories.\n",
        "    Additionally, augment each processed image with random transformations.\n",
        "\n",
        "    :param input_directory: Directory containing the images to be processed and resized.\n",
        "    :param output_directory: Directory to save the processed and resized images.\n",
        "    :param crop_box: A tuple (left, upper, right, lower) defining the crop rectangle.\n",
        "    :param resize_to: A tuple (width, height) defining the size to resize the images to.\n",
        "    :param train_ratio: The ratio of images to be used for training (default is 0.8).\n",
        "    \"\"\"\n",
        "\n",
        "    clear_directory(output_directory)\n",
        "\n",
        "\n",
        "    train_directory = os.path.join(output_directory, \"train\")\n",
        "    test_directory = os.path.join(output_directory, \"test\")\n",
        "    os.makedirs(train_directory)\n",
        "    os.makedirs(test_directory)\n",
        "\n",
        "\n",
        "    class_images = defaultdict(list)\n",
        "    for filename in os.listdir(input_directory):\n",
        "        if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif', '.tiff')):\n",
        "            class_name = filename[:5]\n",
        "            class_images[class_name].append(filename)\n",
        "\n",
        "\n",
        "    min_train_images = min([len(images) for images in class_images.values()]) * train_ratio\n",
        "    min_test_images = min([len(images) for images in class_images.values()]) * (1 - train_ratio)\n",
        "\n",
        "    for class_name, images in class_images.items():\n",
        "        random.shuffle(images)\n",
        "        train_images = images[:int(min_train_images)]\n",
        "        test_images = images[int(min_train_images):int(min_train_images + min_test_images)]\n",
        "\n",
        "        for image_set, subset_directory in zip([train_images, test_images], [train_directory, test_directory]):\n",
        "            class_directory = os.path.join(subset_directory, class_name)\n",
        "            os.makedirs(class_directory, exist_ok=True)\n",
        "\n",
        "            for filename in image_set:\n",
        "                img_path = os.path.join(input_directory, filename)\n",
        "                with Image.open(img_path) as img:\n",
        "                    processed_img = make_non_yellow_and_adjacent_black(img)\n",
        "                    cropped_img = crop_top_down_until_yellow(processed_img, crop_box)\n",
        "                    resized_img = cropped_img.resize(resize_to, Image.LANCZOS)\n",
        "\n",
        "                    resized_img_path = os.path.join(class_directory, filename)\n",
        "                    resized_img.save(resized_img_path)\n",
        "                    print(f\"Processed, cropped, and resized image saved as {resized_img_path}\")\n",
        "\n",
        "                    augment_times = 15\n",
        "                    for i in range(augment_times):\n",
        "                        augmented_img = random_transform(resized_img, resize_to)\n",
        "                        augmented_img_path = os.path.join(class_directory, f\"aug{i}_{filename}\")\n",
        "                        augmented_img.save(augmented_img_path)\n",
        "                        print(f\"Augmented image saved as {augmented_img_path}\")\n",
        "\n",
        "\n",
        "input_directory = \"screenshots\"\n",
        "output_directory = \"cropped_images\"\n",
        "\n",
        "crop_box = (180, 200, 665, 530)\n",
        "resize_to = (256, 256)\n",
        "\n",
        "process_and_resize_images(input_directory, output_directory, crop_box, resize_to)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7SBck5Bol4Ml"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Flatten, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "\n",
        "base_dir = 'cropped_images'\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "test_dir = os.path.join(base_dir, 'test')\n",
        "\n",
        "# Data Augmentation\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    width_shift_range=0.5,\n",
        "    height_shift_range=0.5,\n",
        "    shear_range=0.5,\n",
        "    zoom_range=0.8,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(256, 256),\n",
        "    batch_size=64,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=(256, 256),\n",
        "    batch_size=64,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "# Load the VGG16 model without the top layers\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(256, 256, 3))\n",
        "\n",
        "base_model.trainable = False\n",
        "\n",
        "# Custom layers\n",
        "model = Sequential([\n",
        "    base_model,\n",
        "    Flatten(),\n",
        "    Dense(512, activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.5),\n",
        "    Dense(7, activation='softmax')  # 7 for seven satellites\n",
        "])\n",
        "\n",
        "model.compile(optimizer=Adam(learning_rate=0.001),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Learning rate scheduler\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=5, min_lr=1e-6)\n",
        "early_stopping = EarlyStopping(monitor='val_accuracy', patience=15, restore_best_weights=True)\n",
        "\n",
        "\n",
        "# Training\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=100,\n",
        "    validation_data=test_generator,\n",
        "    callbacks=[reduce_lr, early_stopping]\n",
        ")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DFDfpZQbAFgS"
      },
      "outputs": [],
      "source": [
        "#model.save('my_model.keras')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fnPd086GzCzg"
      },
      "outputs": [],
      "source": [
        "#from tensorflow.keras.models import load_model\n",
        "\n",
        "#model = load_model('Satmodel.keras')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cVaOOqV4o92u"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "\n",
        "base_dir = 'cropped_images'\n",
        "test_dir = os.path.join(base_dir, 'test')\n",
        "\n",
        "\n",
        "img_width, img_height = 256, 256\n",
        "batch_size = 64\n",
        "\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False  # Important to ensure consistency\n",
        ")\n",
        "\n",
        "\n",
        "test_loss, test_acc = model.evaluate(test_generator, steps=len(test_generator))\n",
        "print(f'Test accuracy: {test_acc}')\n",
        "\n",
        "\n",
        "pred_probs = model.predict(test_generator, steps=len(test_generator))\n",
        "\n",
        "\n",
        "pred_classes = np.argmax(pred_probs, axis=1)\n",
        "\n",
        "true_classes = test_generator.classes\n",
        "\n",
        "class_labels = list(test_generator.class_indices.keys())\n",
        "\n",
        "\n",
        "cm = confusion_matrix(true_classes, pred_classes)\n",
        "\n",
        "# Plot the confusion matrix\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(cm, annot=True, cmap='Blues', xticklabels=class_labels, yticklabels=class_labels)\n",
        "plt.xlabel('Predicted labels')\n",
        "plt.ylabel('True labels')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ExkLKCzM_ygp"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
        "\n",
        "def predict_image_class(image_path, model, class_labels, crop_box, resize_to):\n",
        "    img = Image.open(image_path)\n",
        "    processed_img = make_non_yellow_and_adjacent_black(img)\n",
        "    resized_img = processed_img.resize(resize_to, Image.LANCZOS)\n",
        "    img_array = img_to_array(resized_img)\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "    img_array /= 255.0\n",
        "    predictions = model.predict(img_array)\n",
        "    predicted_class = np.argmax(predictions, axis=1)[0]\n",
        "    predicted_label = class_labels[predicted_class]\n",
        "    return predicted_label\n",
        "\n",
        "\n",
        "crop_box = (180, 200, 665, 530)\n",
        "resize_to = (256, 256)\n",
        "\n",
        "\n",
        "# Directory containing the test images\n",
        "test_images_directory = 'testScreenshots'\n",
        "acc = 0\n",
        "count = 0\n",
        "\n",
        "# Predict and print results for each image in the test directory\n",
        "for filename in os.listdir(test_images_directory):\n",
        "    if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif', '.tiff')):\n",
        "        image_path = os.path.join(test_images_directory, filename)\n",
        "        actual_class = filename[:5]  # Adjust based on the actual class naming convention\n",
        "        predicted_label = predict_image_class(image_path, model, class_labels, crop_box, resize_to)\n",
        "        print(f'Image: {filename}, Actual Class: {actual_class}, Predicted Class: {predicted_label}')\n",
        "        if actual_class == predicted_label:\n",
        "            acc += 1\n",
        "        count += 1\n",
        "\n",
        "print(f\"Accuracy: {acc/count:.2f}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}